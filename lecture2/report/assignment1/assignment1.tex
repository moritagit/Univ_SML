\documentclass[class=jsarticle, crop=false, dvipdfmx, fleqn]{standalone}
\input{../../../preamble}
\begin{document}
\section{}

入力\(x \in \mathbb{R}^d\)，期待値\(\mu \in \mathbb{R}^d\)，共分散行列\(\bm{\Sigma} \in \mathbb{R}^{d \times d}\)の
ガウスモデルは次のように表される。
\begin{equation}
	q(\bm{x};\ \bm{\mu},\ \bm{\Sigma}) = \frac{1}{(2\pi)^{d/2} \det (\bm{\Sigma})^{1/2}} \exp(- \frac{1}{2} (\bm{x} - \bm{\mu})^\mathrm{T} \bm{\Sigma}^{-1} (\bm{x} - \bm{\mu}))
\end{equation}
標本\(\qty{x_i}_{i=1}^{n}\)に対して，このモデルの最尤推定量\(\hat{\bm{\mu}}_\mathrm{ML},\ \hat{\bm{\Sigma}}_\mathrm{ML}\)を求める。
対数尤度は次のようになる。
\begin{align}
	\log L(\bm{\mu},\ \bm{\Sigma})
	& = \sum_{i=1}^{n} q(\bm{x}_i;\ \bm{\mu},\ \bm{\Sigma}) \\
	& = \sum_{i=1}^{n} \qty(-\frac{d}{2} \log(2\pi) -\frac{1}{2} \log(\det(\bm{\Sigma})) - \frac{1}{2} \sum_{i=1}^{n} (\bm{x}_i - \bm{\mu})^\mathrm{T} \bm{\Sigma}^{-1} (\bm{x}_i - \bm{\mu})) \\
	& = -\frac{nd}{2} \log(2\pi) - \frac{n}{2} \log(\det(\bm{\Sigma})) - \frac{1}{2} \sum_{i=1}^{n} (\bm{x}_i - \bm{\mu})^\mathrm{T} \bm{\Sigma}^{-1} (\bm{x}_i - \bm{\mu}) \\
\end{align}
ここで，各要素の分散が等しく，共分散が0となる，
すなわち\(\bm{\Sigma} = {\sigma}^2 \bm{I}\)であるガウスモデルを考えると，
\begin{equation}
	q(\bm{x};\ \bm{\mu},\ \bm{\Sigma}) = \frac{1}{(2 \pi {\sigma}^2)^{d/2}} \exp(- \frac{(\bm{x} - \bm{\mu})^\mathrm{T} (\bm{x} - \bm{\mu})}{2 {\sigma}^2})
\end{equation}
となる。
このとき，\(\det(\bm{\Sigma}) = {\sigma}^{2d}\)，\(\Sigma^{-1} = (1/{\sigma}^2) \bm{I}\)から，対数尤度は，
\begin{align}
	\log L(\bm{\mu},\ \sigma)
	& = -\frac{nd}{2} \log(2\pi) - nd \log(\sigma) - \frac{1}{2 {\sigma}^2} \sum_{i=1}^{n} (\bm{x}_i - \bm{\mu})^\mathrm{T} (\bm{x}_i - \bm{\mu}) \\
\end{align}
\(\bm{\mu}, \sigma\)でそれぞれ偏微分して，
\begin{align}
	& \pdv{}{\mu} \qty(\log L(\bm{\mu},\ \sigma)) = \frac{1}{{\sigma}^2} \qty(-n \bm{\mu} + \sum_{i=1}^{n} \bm{x}_i) \\
	& \pdv{}{\sigma} \qty(\log L(\bm{\mu},\ \sigma)) = -\frac{nd}{\sigma} + \frac{1}{{\sigma}^3} \sum_{i=1}^{n} (\bm{x}_i - \bm{\mu})^\mathrm{T} (\bm{x}_i - \bm{\mu})
\end{align}
これらをそれぞれ\(\bm{0},\ 0\)と置くことで，\(L\)に最大値を与える\(\bm{\mu},\ \sigma\)が得られる。
つまり，
\begin{align}
	\hat{\bm{\mu}}_\mathrm{ML} & = \frac{1}{n} \sum_{i=1}^{n} \bm{x}_i \\
	{\hat{\sigma}_\mathrm{ML}}^2 
		& = \frac{1}{nd} \sum_{i=1}^{n} (\bm{x}_i - \bm{\mu})^\mathrm{T} (\bm{x}_i - \bm{\mu}) \\
		& = \frac{1}{nd} \sum_{i=1}^{n} \sum_{j=1}^{d} \qty(x_i^{(j)} - {\hat{\mu}_\mathrm{ML}}^{(j)})^2
\end{align}


\end{document}